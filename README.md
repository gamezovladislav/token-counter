# üî¢ Token Counter ‚ú®

> *Vibe check your AI costs with this super lit token counter!* üí∏

A simple yet powerful utility for counting tokens in text files for AI language models. This tool supports both OpenAI and Anthropic models, providing accurate token counts for cost estimation and context length management. No cap!

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.6+-blue.svg" alt="Python 3.6+">
  <img src="https://img.shields.io/badge/OpenAI-Compatible-green.svg" alt="OpenAI Compatible">
  <img src="https://img.shields.io/badge/Anthropic-Compatible-purple.svg" alt="Anthropic Compatible">
</div>

## ‚ú® Features

- üìÅ Count tokens in individual files or entire directories
- ü§ñ Support for multiple AI models:
  - **OpenAI models**: gpt-4, gpt-4o, gpt-4.1, o1, o3, o4-mini
  - **Anthropic models**: claude-3-7-sonnet-latest (default), claude-3-5-haiku-latest, claude-3-5-sonnet-latest, claude-3-opus-latest, claude-sonnet-4-0, claude-opus-4-0, and many more version-specific models
- üîÑ Automatic selection of the appropriate tokenizer based on the specified model
- üåà Colorized output for better readability
- üìä Detailed summary statistics
- üõü Fallback counting method when tokenizer libraries are not available or encounter errors

## üöÄ Installation

> *Three easy steps and you're ready to flex!* üíØ

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/token-counter.git
   cd token-counter
   ```

2. (Optional) Create a virtual environment:
   
   **Windows:** ü™ü
   ```bash
   python -m venv venv
   venv\Scripts\activate
   ```
   
   **macOS/Linux:** üêß
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## üìã Requirements

> *Minimal dependencies, maximum vibes* ‚úåÔ∏è

- üêç Python 3.6 or higher
- üü¢ tiktoken (for OpenAI models)
- üü£ anthropic (for Anthropic models)
- üå± python-dotenv (for .env file configuration)

## üî• Usage

> *Let's get this token bread!* üçû

### üîç Basic Usage

Count tokens in a single file:
```bash
python count_tokens.py path/to/file.txt
```

Count tokens in a directory (recursively):
```bash
python count_tokens.py path/to/directory
```

### ü§ñ Specifying a Model

Count tokens using a specific model:
```bash
python count_tokens.py path/to/file.txt --model gpt-4
```

#### Available Models:

| üü¢ **OpenAI** | üü£ **Anthropic** |
|--------------|-----------------|
| gpt-4        | claude-3-7-sonnet-latest (default) |
| gpt-4o       | claude-3-5-haiku-latest |
| gpt-4.1      | claude-3-5-sonnet-latest |
| o1           | claude-3-opus-latest |
| o3           | claude-sonnet-4-0 |
| o4-mini      | claude-opus-4-0 |
|              | *and many more version-specific models* |

## ‚å®Ô∏è Command-line Options

```bash
usage: count_tokens.py [-h] [--model MODEL] [--pretty-output [BOOL]] path

Count tokens in text files for AI models

positional arguments:
  path                  Path to file or directory to analyze

optional arguments:
  -h, --help            show this help message and exit
  --model MODEL, -m MODEL
                        AI model for token counting (default: from .env or claude-3-7-sonnet-latest)
  --pretty-output, -p [BOOL]
                        Enable/disable colorized output (default from PRETTY_OUTPUT or True). When provided
                        without a value, it enables colors. Accepted values: true/false, 1/0, yes/no, on/off.
```

### Pretty Output Toggle
- CLI (single property):
  - `count_tokens.py path` -> colors ON (default from PRETTY_OUTPUT or True)
  - `count_tokens.py --pretty-output path` -> colors ON
  - `count_tokens.py --pretty-output false path` -> colors OFF
  - Accepted values for BOOL: true/false, 1/0, yes/no, on/off (case-insensitive)
- Environment: set `PRETTY_OUTPUT=false` to change the default (accepted values: 1/0, true/false, yes/no, on/off; default: true).

## ‚öôÔ∏è Configuration with .env File

> *Customize your token counting experience!* üõ†Ô∏è

You can configure the token counter using a `.env` file in the project root directory. Create a copy of the `.env.example` file and rename it to `.env`:

```bash
cp .env.example .env
```

### Available Configuration Options:

| Variable | Description | Example |
|----------|-------------|---------|
| `ANTHROPIC_API_KEY` | Anthropic API key used for Claude models | `sk-ant-...` |
| `CLAUDE_API_KEY` | Optional alias for Anthropic API key (fallback if ANTHROPIC_API_KEY is not set) | `sk-ant-...` |
| `OPENAI_MODELS` | Comma-separated list of available OpenAI models | `o1,o3,o4-mini,gpt-4.1,gpt-4o,gpt-4` |
| `ANTHROPIC_MODELS` | Comma-separated list of available Anthropic models | `claude-3-7-sonnet-latest,claude-3-5-haiku-latest` |
| `DEFAULT_MODEL` | Default model to use when not specified | `claude-3-7-sonnet-latest` |
| `IGNORE_DIRS` | Directories to ignore during processing | `.git,.idea,.vscode,__pycache__,venv` |
| `IGNORE_EXTENSIONS` | File extensions to ignore during processing | `.jpg,.jpeg,.png,.gif,.exe` |
| `PRETTY_OUTPUT` | Toggle colorized console output (boolean) | `true` or `false` |

### Example .env File:

```
# Token Counter Configuration

# Anthropic API Key (required when using Claude models)
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
# Optional alias if you prefer: CLAUDE_API_KEY=sk-ant-your-api-key-here

# OpenAI Models (comma-separated list)
OPENAI_MODELS=o1,o3,o4-mini,gpt-4.1,gpt-4o,gpt-4

# Anthropic Models (comma-separated list)
ANTHROPIC_MODELS=claude-3-7-sonnet-latest,claude-3-5-haiku-latest,claude-3-opus-latest

# Default Model (must be included in one of the model lists above)
DEFAULT_MODEL=gpt-4o

# Directories to ignore (comma-separated list)
IGNORE_DIRS=.git,.idea,.vscode,__pycache__,venv,node_modules,.venv

# File extensions to ignore (comma-separated list)
IGNORE_EXTENSIONS=.jpg,.jpeg,.png,.gif,.exe,.dll,.pyc,.pyo

# Pretty output (colors): true/false (default true)
PRETTY_OUTPUT=true
```

## üíØ Examples

> *Check out these sick examples!* üî•

<details open>
<summary>üîç <b>Example 1:</b> Count tokens in a single file</summary>

```bash
$ python count_tokens.py sample.txt
============================================================
  TOKEN COUNTER
  Model: claude-3-7-sonnet-latest
============================================================
File: sample.txt
  Characters: 239
  Tokens: 49

Summary:
Characters: 239
Tokens: 49
============================================================
```
</details>

<details>
<summary>üü£ <b>Example 2:</b> Count tokens with specific Claude model</summary>

```bash
$ python count_tokens.py sample_claude.txt --model claude-3-opus-latest
============================================================
  TOKEN COUNTER
  Model: claude-3-opus-latest
============================================================
File: sample_claude.txt
  Characters: 488
  Tokens: 101

Summary:
Characters: 488
Tokens: 101
============================================================
```
</details>

<details>
<summary>üü¢ <b>Example 3:</b> Count tokens with OpenAI model</summary>

```bash
$ python count_tokens.py sample.txt --model gpt-4
============================================================
  TOKEN COUNTER
  Model: gpt-4
============================================================
File: sample.txt
  Characters: 239
  Tokens: 45

Summary:
Characters: 239
Tokens: 45
============================================================
```
</details>

<details>
<summary>üìÅ <b>Example 4:</b> Count tokens in a directory</summary>

```bash
$ python count_tokens.py ./docs
============================================================
  TOKEN COUNTER
  Model: claude-3-7-sonnet-latest
============================================================

Processing directory: ./docs
Using model: claude-3-7-sonnet-latest
File: ./docs/introduction.txt
  Characters: 1250
  Tokens: 245
File: ./docs/tutorial.txt
  Characters: 3500
  Tokens: 680

Summary:
Files processed: 2
Total characters: 4 750
Total tokens: 925
============================================================
```
</details>

## üß† How It Works

> *The secret sauce behind the magic!* ‚ú®

The token counter works by:

1. üìñ Reading the content of text files
2. üîÑ Using the appropriate tokenizer library based on the selected model:
   - üü¢ **tiktoken** for OpenAI models (gpt-4, gpt-4o, etc.)
   - üü£ **anthropic** for Anthropic models (claude-3-7-sonnet-latest, etc.)
3. üßÆ Counting the tokens using the selected tokenizer
4. üìä Providing a summary of the results

### üõü Fallback Mechanism

<details>
<summary><b>What happens if something goes wrong?</b> (click to expand)</summary>

If the tokenizer libraries encounter errors (such as initialization issues or compatibility problems), the tool automatically falls back to a simple regex-based token counting method. This ensures that the tool continues to function even when:

- ‚ùå The required libraries are not installed
- üîÑ There are version compatibility issues
- üåê Environment-specific configuration problems occur

When the fallback method is used, a warning message is displayed, but the tool continues to provide approximate token counts.
</details>

## üí∞ Why Token Counting Matters

> *Know your tokens, save your coins!* üí∏

Accurate token counting is **super important** for:

- üíµ Estimating API costs when using AI language models
- üìè Ensuring your prompts fit within model context limits
- üöÄ Optimizing prompt design for efficiency

## üë• Contributing

> *Join the squad and make this tool even more fire!* üî•

Contributions are welcome! Please feel free to submit a Pull Request.

## üìú License

This project is licensed under the MIT License - see the LICENSE file for details.


## üß© Usage as GitHub Action

> This repository can be used as a step (composite action) in other repositories.
>
> It's recommended to pin the version: `@v1` or specific release `@v1.2.3`. For details, see VERSIONING.md.

### Option A. Direct action usage in workflow

```yaml
name: Token Count
on:
  workflow_dispatch:

jobs:
  count:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Count tokens
        id: token_counter
        uses: gamezovladislav/token-counter@v0.1
        with:
          path: .
          model: o3
          pretty_output: 'false'

      - name: Upload summary artifact (optional)
        uses: actions/upload-artifact@v4
        with:
          name: token-summary
          path: ${{ steps.token_counter.outputs.summary_file }}
```

Input parameters:
- path ‚Äî path within repository for analysis (default: '.')
- model ‚Äî tokenizer model identifier (e.g., gpt-4o, gpt-4, claude-3-7-sonnet-latest)
- pretty_output ‚Äî true/false, enable colored output (false is better for artifacts)

Action provides outputs:
- raw_output ‚Äî string with raw output
- summary_file ‚Äî path to generated results file

### Option B. Reusable workflow (workflow_call)

This repository includes a ready-to-use reusable workflow `.github/workflows/token_count_reusable.yml`.
You can call it from another repository like this:

```yaml
name: Token Count via Reusable
on:
  workflow_dispatch:

jobs:
  call-token-count:
    uses: <owner>/<repo>/.github/workflows/token_count_reusable.yml@v1  # replace owner/repo
    with:
      path: .
      model: gpt-4o
```

### Option C. Token counting in EXTERNAL repository

To count tokens in an external repository, you need to checkout it during the job and specify the path to it:

```yaml
name: Token Count (external repo)
on:
  workflow_dispatch:
    inputs:
      target_repo:
        description: "owner/repo of target repository"
        required: true
        type: string
      target_ref:
        description: "branch/tag/sha (default: main)"
        required: false
        default: main
        type: string

jobs:
  count:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout action repo
        uses: actions/checkout@v4

      - name: Checkout target repository
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.target_repo }}
          ref: ${{ inputs.target_ref }}
          path: target
          # For private repos add PAT with contents:read scope
          # token: ${{ secrets.REPO_READ_TOKEN }}

      - name: Count tokens in target
        uses: ./
        with:
          path: target
          model: gpt-4o
          pretty_output: 'false'

      - name: Upload result artifact
        uses: actions/upload-artifact@v4
        with:
          name: token-summary
          path: token_summary.txt
```

Notes:
- For private external repositories use personal token `REPO_READ_TOKEN` with `contents:read` scope.
- Supported models from predefined lists (see count_tokens.py). Specifying an unknown model will cause argument validation error.

### Quick start in this repository

- Run manually the workflow `Token Count (current repo)` in the Actions section.
- Or call the reusable workflow `token_count_reusable.yml` from another repository.

### Versioning

Versioning scheme and release publication recommendations are described in the VERSIONING.md file. Please pin the Action to `@v1` or to a specific release tag.

---

<div align="center">
  <p>Made with ‚ù§Ô∏è for the AI community</p>
  <p>¬© 2025 - Stay vibin'! ‚úåÔ∏è</p>
</div>